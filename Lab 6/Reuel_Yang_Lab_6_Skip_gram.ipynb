{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDlU-kLCKDVZ"
      },
      "source": [
        "NAME = \"Reuel Yang\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW9zL4V6KDVc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9a0ec075584699a44c46933457b0a8ba",
          "grade": false,
          "grade_id": "cell-a910b376742d04c0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ECD5r2hFKDVd"
      },
      "source": [
        "# Lab 6: Skip Gram\n",
        "\n",
        "**Please read the following instructions very carefully**\n",
        "\n",
        "## Working on the assignment / FAQs\n",
        "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments)\n",
        "- The type of question and the points they carry are indicated in each question cell\n",
        "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
        "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
        "- You can delete the `raise NotImplementedError()`\n",
        "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
        "- That's about it. Happy coding!\n",
        "\n",
        "\n",
        "Available software:\n",
        " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
        "\n",
        "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
          "grade": false,
          "grade_id": "cell-bf780e597c0216c8",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Vsocwry-KDVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "91dfb319-590d-4398-8354-c1cd86610a7a"
      },
      "source": [
        "!pip install gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load('word2vec-google-news-300') # this step might take ~10-15 minutes"
      ],
      "metadata": {
        "id": "TIcyAqlk6Qpy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3855902b-a34e-4b97-b05b-86d7206f5a44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "47031c66b74746d23ccc5e8369446a4b",
          "grade": false,
          "grade_id": "cell-3f89500615a0096f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZF74G9bDKDVh"
      },
      "source": [
        "### **Q1 (1 point)**\n",
        "Find the cosine similarity between the following word pairs\n",
        "\n",
        "- (France, England)\n",
        "- (come, go)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
          "grade": false,
          "grade_id": "cell-fbbe575f8f5a6368",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "SZD5ZaMvKDVk"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "similarity_pair1 = model.similarity('France', 'England')\n",
        "similarity_pair2 = model.similarity('come', 'go')\n",
        "similarity_pair3 = model.similarity('England', 'London')\n",
        "similarity_pair4 = model.similarity('France', 'Rocket')\n",
        "similarity_pair5 = model.similarity('big', 'bigger')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
          "grade": true,
          "grade_id": "cell-929d59ed5d67f618",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "tFUPLSK7KDVp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83c41d71-6e1d-4df1-ddea-066ae8173566"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39804944 0.6604678 0.43992856 0.07114174 0.68423855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a7f270405ddf9ecbffde36e6c096b818",
          "grade": false,
          "grade_id": "cell-ccd6618b4fac3715",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZcqpWCjJKDVs"
      },
      "source": [
        "### **Q2 (1 point)**\n",
        "Write an expression to extract the vector representations of the words:\n",
        "\n",
        "- France\n",
        "- England\n",
        "- smaller\n",
        "- bigger\n",
        "- rocket\n",
        "- big\n",
        "\n",
        "Get only the first 5 elements for each vector representation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
        "vector_1 = model['France'][:5]\n",
        "vector_2 = model['England'][:5]\n",
        "vector_3 = model['smaller'][:5]\n",
        "vector_4 = model['bigger'][:5]\n",
        "vector_5 = model['rocket'][:5]\n",
        "vector_6 = model['big'][:5]"
      ],
      "metadata": {
        "id": "ElgK5QLuGi6S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "401940f859774b3c1ec48338fa15682e",
          "grade": true,
          "grade_id": "cell-6f34229370fa873f",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "Hkj2ROGTKDVv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "be96acf6-5443-4eee-f732-9fad41de592e"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(vector_1)\n",
        "print(vector_2)\n",
        "print(vector_3)\n",
        "print(vector_4)\n",
        "print(vector_5)\n",
        "print(vector_6)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
            "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
            "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
            "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
            "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
            "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
          "grade": false,
          "grade_id": "cell-4ad44071d3785409",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "2UBnMwiXKDVy"
      },
      "source": [
        "### **Q3 (1 point)**\n",
        "Find the euclidean distances between the word pairs :\n",
        "\n",
        "- (France, England)\n",
        "- (smaller, bigger)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "eu_dist1 = np.linalg.norm(model['France'] - model['England'])\n",
        "eu_dist2 = np.linalg.norm(model['smaller'] - model['bigger'])\n",
        "eu_dist3 = np.linalg.norm(model['England'] - model['London'])\n",
        "eu_dist4 = np.linalg.norm(model['France'] - model['Rocket'])\n",
        "eu_dist5 = np.linalg.norm(model['big'] - model['bigger'])"
      ],
      "metadata": {
        "id": "JYUdXmCOMg45"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "17796eb5de342e8f8e841aa137a2c41c",
          "grade": true,
          "grade_id": "cell-15ffa50b82de21ad",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "HsSg0l2UKDV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "68db2737-a6b5-49df-adc7-dbaa0395c895"
      },
      "source": [
        "#This is an autograded cell, do not edit / delete\n",
        "print(eu_dist1)\n",
        "print(eu_dist2)\n",
        "print(eu_dist3)\n",
        "print(eu_dist4)\n",
        "print(eu_dist5)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0151067\n",
            "1.8618743\n",
            "2.8752837\n",
            "3.892071\n",
            "1.9586496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "afc0e843c7545e2df83448feda9f28f5",
          "grade": false,
          "grade_id": "cell-7cd8b9b67386376d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "XvO2iU7QKDWA"
      },
      "source": [
        "### **Q4 (1 point)**\n",
        "Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
        "- (King - Man + Queen)\n",
        "- (bigger - big + small)\n",
        "- (waiting - wait + run)\n",
        "- (Texas + Milwaukee â€“ Wisconsin)\n",
        "\n",
        "Note: If your kernel crashes due to low memory and restarts, reload the model from the top and try running this part again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "50ef096feb166865434fe2fca3d41f99",
          "grade": false,
          "grade_id": "cell-b72201968c5fd1ec",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "jCxWmA1eKDWB"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "closest1 = model.most_similar(positive=['King', 'Queen'], negative=['Man'])[:2]\n",
        "closest2 = model.most_similar(positive=['bigger', 'small'], negative=['big'])[:2]\n",
        "closest3 = model.most_similar(positive=['waiting', 'run'], negative=['wait'])[:2]\n",
        "closest4 = model.most_similar(positive=['Texas', 'Milwaukee'], negative=['Wisconsin'])[:2]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f9c5ff502264f29d2632c6387f92686a",
          "grade": true,
          "grade_id": "cell-b69718ab0e1470bc",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "io9elfD8KDWE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8ae7a482-e34a-4b03-c506-f78cb218162f"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(closest1)\n",
        "print(closest2)\n",
        "print(closest3)\n",
        "print(closest4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Queen_Elizabeth', 0.5257916450500488), ('monarch', 0.5004087090492249)]\n",
            "[('larger', 0.7402471303939819), ('smaller', 0.7329993844032288)]\n",
            "[('running', 0.5654535889625549), ('runs', 0.49639999866485596)]\n",
            "[('Houston', 0.7767744064331055), ('Fort_Worth', 0.7270511388778687)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
          "grade": false,
          "grade_id": "cell-73dca0e2072fef91",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "erUu4u71KDWJ"
      },
      "source": [
        "### **Q5 (3 points)**\n",
        "Using the vectors for the words in the Google News dataset, apply K-means clustering (K=2) and find the top 5 most representative words/phrases of each cluster.\n",
        "\n",
        "*Note: Since there are ~3Mil words in the vocabulary, you can downsample it to 25k randomly selected words*  \\\\\n",
        "*Hint: The \"similar_by_vector\" method might be useful*\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 0 with the code / value; Do not delete this cell\n",
        "import random\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vocab_keys = list(model.key_to_index.keys())\n",
        "randomly_selected_words = random.sample(vocab_keys, 25000)\n",
        "subset_word_vectors = [model[word] for word in randomly_selected_words]\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init='auto')\n",
        "kmeans.fit(subset_word_vectors)\n",
        "\n",
        "top_representative_words = {}\n",
        "for cluster_label in range(2):\n",
        "    centroid = kmeans.cluster_centers_[cluster_label]\n",
        "    similar_words = model.similar_by_vector(centroid, topn=5)\n",
        "    top_representative_words[cluster_label] = similar_words\n",
        "\n",
        "most_rep_cluster1 = top_representative_words[0]\n",
        "most_rep_cluster2 = top_representative_words[1]"
      ],
      "metadata": {
        "id": "iqTEPYr_YuRu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "7ecef46689f11d4d0a6fed72e049235f",
          "grade": true,
          "grade_id": "cell-80b177848b8b0212",
          "locked": false,
          "points": 3,
          "schema_version": 1,
          "solution": true
        },
        "id": "M3jN02fOKDWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "03510f37-3545-4d70-a86c-f726deb79672"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(most_rep_cluster1)\n",
        "print(most_rep_cluster2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('http_dol##.net_index###.html_http', 0.9182074666023254), ('dol##.net_index####.html_http_dol##.net', 0.9084749817848206), ('index###.html_http_dol##.net_index###.html', 0.9070622324943542), ('Deltagen_undertakes', 0.9052171111106873), ('By_TRICIA_SCRUGGS', 0.9017032980918884)]\n",
            "[('Emil_Protalinski_Published', 0.9214745759963989), ('By_HuDie_####-##-##', 0.9198623895645142), ('By_QianMian_####-##-##', 0.9184156656265259), ('BY_GEOFF_KOHL', 0.9172717332839966), ('By_XiaoBing_####-##-##', 0.9158840775489807)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0467b27a0f59504cbb62b851a002386f",
          "grade": false,
          "grade_id": "cell-5b2a5e8ff6c74323",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rmdtLoHkKDWR"
      },
      "source": [
        "### **Q6 (1 point)**\n",
        "What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The skipgram model uses Cross-entropy loss function. Skip-grams have a single target word as input and context words as output. The function is calculating the probability of observing a context word from the context window given a target word. The loss function aims to minimize the difference between the positive sample probability (probability of observing true context words) and the negative sample probability (probability of observing randomly sampled words from the vocabulary as context words)."
      ],
      "metadata": {
        "id": "_05FXWh8LKud"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
          "grade": true,
          "grade_id": "cell-90cc4b2c0ae8e2c2",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "SyOASYXOKDWS"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c14f6069f64cc86ab6e384d28df270d8",
          "grade": false,
          "grade_id": "cell-74a177caaabb5009",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "dbpuJx9CKDWV"
      },
      "source": [
        "### **Bonus Question (1 point)**\n",
        "Find at least 2 interesting word vec combinations like the ones given in Q4\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
          "grade": true,
          "grade_id": "cell-7351297993d72e83",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "pQM8C_T7KDWW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cfbfcf54-4ed0-44d8-da67-0db1be5b76cc"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "closest5 = model.most_similar(positive=['Nissan', 'Drift'], negative=['America'])[:2]\n",
        "closest6 = model.most_similar(positive=['Reggaeton', 'Korean', 'artist'], negative=['unpopular'])[:2]\n",
        "print(closest5)\n",
        "print(closest6)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Proton_Satria', 0.47245484590530396), ('Toyota_Auris', 0.47118985652923584)]\n",
            "[('Ho_Quynh_Huong', 0.5279245972633362), ('pansori', 0.5203095078468323)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULdYIXstC9ZD"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}